{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e15088dd-9d2d-4b03-807e-73784de51ebf",
   "metadata": {},
   "source": [
    "\n",
    "## Task 1. Prepare the training data\n",
    "\n",
    "The initial Vertex AI dashboard illustrates the major stages to train and deploy a ML model: prepare the training data, train the model, and get predictions. Later, the dashboard displays your recent activities, such as the recent datasets, models, predictions, endpoints, and notebook instances.\n",
    "\n",
    "Create a dataset\n",
    "1. In the Google Cloud console, on the Navigation menu, click Vertex AI > Datasets.\n",
    "2. Click Create dataset.\n",
    "3. Give dataset a name LoanRisk.\n",
    "4. For the data type and objective, click Tabular, and then select Regression/classification.\n",
    "5. Click Create.\n",
    "\n",
    "Upload data\n",
    "There are three options to import data in Vertex AI:\n",
    "\n",
    "1. Upload a local file from your computer.\n",
    "2. Select files from Cloud Storage.\n",
    "3. Select data from BigQuery.\n",
    "For convenience, the dataset is already uploaded to Cloud Storage.\n",
    "\n",
    "For the data source, select Select CSV files from Cloud Storage.\n",
    "For Import file path, enter: spls/cbl455/loan_risk.csv\n",
    "\n",
    "Click Continue.\n",
    "\n",
    "Note: You can also configure this page by clicking Datasets on the left menu and then selecting the dataset name on the Datasets page.\n",
    "\n",
    "Generate statistics\n",
    "1. To see the descriptive statistics for each column of your dataset, click Generate statistics .\n",
    "2. Generating the statistics might take a few minutes, especially the first time.\n",
    "When the statistics are ready, click each column name to display analytical charts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12598274-ae08-4751-bf67-2c0d60c18135",
   "metadata": {},
   "source": [
    "\n",
    "## Task 2. Train your model\n",
    "\n",
    "\n",
    "With a dataset uploaded, you're ready to train a model to predict whether a customer will repay the loan.\n",
    "\n",
    "Click Train new model and select Other .\n",
    "Training method\n",
    "1. The dataset is already named LoanRisk.\n",
    "2. For Objective, select Classification.\n",
    "You select classification instead of regression because you are predicting a distinct number (whether a customer will repay a loan: 0 for repay, 1 for default/not repay) instead of a continuous number.\n",
    "3. Click Continue.\n",
    "\n",
    "   \n",
    "Model details\n",
    "\n",
    "Specify the name of the model and the target column.\n",
    "\n",
    "1. Give the model a name, such as LoanRisk.\n",
    "2. For Target column, select Default .\n",
    "(Optional) Explore Advanced options to determine how to assign the training vs. testing data and specify the encryption.\n",
    "3. Click Continue.\n",
    "4. For Add features, click Continue.\n",
    "5. Training options\n",
    "6. Specify which columns you want to include in the training model. For example, ClientID might be irrelevant to predict loan risk.\n",
    "\n",
    "Training Options\n",
    "1. Click the minus sign on the ClientID row to exclude it from the training model.\n",
    "2. (Optional) Explore Advanced options to select different optimization objectives.\n",
    "For more information about optimization objectives for tabular AutoML models, refer to the Optimization Objectives for tabular AutoML Models guide.\n",
    "3. Click Continue.\n",
    "\n",
    "   \n",
    "Compute and pricing\n",
    "1. For Budget, which represents the number of node hours for training, enter 1.\n",
    "Training your AutoML model for 1 compute hour is typically a good start for understanding whether there is a relationship between the features and label you've selected. From there, you can modify your features and train for more time to improve model performance.\n",
    "2. Leave early stopping Enabled.\n",
    "3. Click Start training.\n",
    "\n",
    "Depending on the data size and the training method, the training can take from a few minutes to a couple of hours. Normally you would receive an email from Google Cloud when the training job is complete. However, in the Qwiklabs environment, you will not receive an email.\n",
    "\n",
    "To save the waiting for the model training, you download a pre-trained model in Task 5 to get predictions in Task 6. This pre-trained model is the training result following the same steps from Task 1 to Task 2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a3bde1-6766-4e34-bdd5-c81f488bfc56",
   "metadata": {},
   "source": [
    "\n",
    "## Task 3. Evaluate the model performance (demonstration only)\n",
    "\n",
    "Vertex AI provides many metrics to evaluate the model performance. You focus on three:\n",
    "\n",
    "Precision/Recall curve\n",
    "Confusion Matrix\n",
    "Feature Importance\n",
    "\n",
    "Note: If you had a model trained, you could navigate to the Model Registry tab in Vertex AI.\n",
    "1. Navigate to the Model Registry.\n",
    "2. Click on the model you just trained.\n",
    "3. Browse the Evaluate tab.\n",
    "However, in this lab, you can skip this step since you use a pre-trained model.\n",
    "\n",
    "\n",
    "The precision/recall curve\n",
    "The confidence threshold determines how a ML model counts the positive cases. A higher threshold increases the precision, but decreases recall. A lower threshold decreases the precision, but increases recall.\n",
    "\n",
    "You can manually adjust the threshold to observe its impact on precision and recall and find the best tradeoff point between the two to meet your business needs.\n",
    "\n",
    "\n",
    "The confusion matrix\n",
    "A confusion matrix tells you the percentage of examples from each class in your test set that your model predicted correctly.\n",
    "\n",
    "Confusion matrix table displaying true label and predicted label classifications\n",
    "The confusion matrix shows that your initial model is able to predict 100% of the repay examples and 87% of the default examples in your test set correctly, which is not too bad.\n",
    "\n",
    "You can improve the percentage by adding more examples (more data), engineering new features, and changing the training method, etc.\n",
    "\n",
    "\n",
    "The feature importance\n",
    "In Vertex AI, feature importance is displayed through a bar chart to illustrate how each feature contributes to a prediction. The longer the bar, or the larger the numerical value associated with a feature, the more important it is.\n",
    "\n",
    "These feature importance values could be used to help you improve your model and have more confidence in its predictions. You might decide to remove the least important features next time you train a model or to combine two of the more significant features into a feature cross to see if this improves model performance.\n",
    "\n",
    "Feature importance is just one example of Vertex AIâ€™s comprehensive machine learning functionality called Explainable AI. Explainable AI is a set of tools and frameworks to help understand and interpret predictions made by machine learning models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0d4d3f-faff-4fb6-985d-71677b955396",
   "metadata": {},
   "source": [
    "\n",
    "## Task 4. Deploy the model (demonstration only)\n",
    "\n",
    "Note: You will not deploy the model to an endpoint because the model training can take an hour. Here you can review the steps you would perform in a production environment.\n",
    "\n",
    "Now that you have a trained model, the next step is to create an endpoint in Vertex. A model resource in Vertex can have multiple endpoints associated with it, and you can split traffic between endpoints.\n",
    "\n",
    "# Create and define an endpoint\n",
    "1. On your model page, click Deploy & test, and then click Deploy to Endpoint.\n",
    "2. For Endpoint name, type LoanRisk\n",
    "3. Click Continue.\n",
    "\n",
    "# Model settings and monitoring\n",
    "1. Leave the traffic splitting settings as-is.\n",
    "2. For Machine type, select e2-standard-8, 8 vCPUs, 30 GiB memory.\n",
    "3. For Explainability Options, click Feature attribution.\n",
    "4. Click Done.\n",
    "5. Click Continue.\n",
    "6. In Model monitoring, click Continue.\n",
    "7. In Model objectives > Training data source, select Vertex AI dataset.\n",
    "8. Select your dataset from the drop down menu.\n",
    "9. In Target column, type Default\n",
    "10. Leave the remaining settings as-is and click Deploy.\n",
    "\n",
    "Your endpoint will take a few minutes to deploy. When it is completed, a green check mark will appear next to the name.\n",
    "\n",
    "Now you're ready to get predictions on your deployed model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01588888-92b3-4fc2-a7a4-57d5b48aaa6e",
   "metadata": {},
   "source": [
    "\n",
    "## Task 5. SML Bearer Token\n",
    "\n",
    "# Retrieve your Bearer Token\n",
    "\n",
    "To allow the pipeline to authenticate, and be authorized to call the endpoint to get the predictions, you will need to provide your Bearer Token.\n",
    "\n",
    "Note: Follow the instructions below to get your token. If you have issues getting the Bearer Token, this can be due to cookies in the incognito window. If this is happening to you, try this step in a non-incognito window.\n",
    "\n",
    "1. Log in to gsp-auth-kjyo252taq-uc.a.run.app.\n",
    "2. When logging in, use your student email address and password.\n",
    "3. Click the Copy button. This will copy a very long token to your clipboard.\n",
    "\n",
    "Note: This token will only be available for about 60 seconds, so copy and and move on to the next steps.\n",
    "\n",
    "Note: If you have issues getting the Bearer Token, this can be due to cookies in the incognito window - try in a non-incognito window.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747f7a82-47f6-4ba1-a16a-c1e6aa021beb",
   "metadata": {},
   "source": [
    "\n",
    "## Task 6. Get predictions\n",
    "\n",
    "In this section, use the Shared Machine Learning (SML) service to work with an existing trained model.\n",
    "\n",
    "ENVIRONMENT VARIABLE\t           VALUE\n",
    "AUTH_TOKEN\t                 Use the value from the previous section\n",
    "ENDPOINT\t                 https://sml-api-vertex-kjyo252taq-uc.a.run.app/vertex/predict/tabular_classification\n",
    "INPUT_DATA_FILE\t             INPUT-JSON\n",
    "\n",
    "\n",
    "To use the trained model, you will need to create some environment variables.\n",
    "\n",
    "1. Open a Cloud Shell window.\n",
    "   \n",
    "2. Replace INSERT_SML_BEARER_TOKEN with the bearer token value from the previous section:\n",
    "export AUTH_TOKEN=\"INSERT_SML_BEARER_TOKEN\"\n",
    "\n",
    "3. Download the lab assets:\n",
    "gcloud storage cp gs://spls/cbl455/cbl455.tar.gz .\n",
    "\n",
    "4. Extract the lab assets:\n",
    "tar -xvf cbl455.tar.gz\n",
    "\n",
    "5. Create an ENDPOINT environment variable:\n",
    "export ENDPOINT=\"https://sml-api-vertex-kjyo252taq-uc.a.run.app/vertex/predict/tabular_classification\"\n",
    "\n",
    "6. Create a INPUT_DATA_FILE environment variable:\n",
    "export INPUT_DATA_FILE=\"INPUT-JSON\" \n",
    "\n",
    "Note: After the lab assets are extracted, take a moment to review the contents.\n",
    "The INPUT-JSON file is used to provide Vertex AI with the model data required. Alter this file to generate custom predictions.\n",
    "\n",
    "The smlproxy application is used to communicate with the backend.\n",
    "\n",
    "The file INPUT-JSON is composed of the following values:\n",
    "age\t     ClientID\t   income\t   loan\n",
    "40.77\t   997\t      44964.01\t 3944.22\n",
    "\n",
    "7. Test the SML Service by passing the parameters specified in the environment variables.\n",
    "\n",
    "8. Perform a request to the SML service:\n",
    "./smlproxy tabular \\\n",
    "  -a $AUTH_TOKEN \\\n",
    "  -e $ENDPOINT \\\n",
    "  -d $INPUT_DATA_FILE\n",
    "\n",
    "This query should result in a response similar to this:\n",
    "\n",
    "  SML Tabular HTTP Response:\n",
    "  2022/01/10 15:04:45 {\"model_class\":\"0\",\"model_score\":0.9999981}\n",
    "\n",
    "Alter the INPUT-JSON file to test a new scenario:\n",
    "age\tClientID\tincome\tloan\n",
    "30.00\t998\t50000.00\t20000.00\n",
    "\n",
    "10. Test the SML Service by passing the parameters specified in the environment variables.\n",
    "\n",
    "11. Edit the file INPUT-JSON and replace the original values.\n",
    "\n",
    "12. Perform a request to the SML service:\n",
    "./smlproxy tabular \\\n",
    "  -a $AUTH_TOKEN \\\n",
    "  -e $ENDPOINT \\\n",
    "  -d $INPUT_DATA_FILE\n",
    "\n",
    "In this case, assuming that the person's income is 50,000, age 30, and loan 20,000, the model predicts that this person will repay the loan.\n",
    "\n",
    "This query should result in a response similar to this:\n",
    "\n",
    "  SML Tabular HTTP Response:\n",
    "  2022/01/10 15:04:45 {\"model_class\":\"0\",\"model_score\":1.0322887E-5}\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c74952d-f414-4d3d-9770-3e7fe3fa572a",
   "metadata": {},
   "source": [
    "Commands used in cloud shell window (Terminal)\n",
    "\n",
    "student_00_a1265dda319f@cloudshell:~ (qwiklabs-gcp-01-839553806d81)$ export AUTH_TOKEN=\"eyJhbGciOiJSUzI1NiIsImtpZCI6ImVkODA2ZjE4NDJiNTg4MDU0YjE4YjY2OWRkMWEwOWE0ZjM2N2FmYzQiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJhY2NvdW50cy5nb29nbGUuY29tIiwiYXpwIjoiMTAzMDExNTE5NDYyMC11c2dqZDVmZmJrZWp0MzBlYmdiOXY5azR2YXExNDFxdS5hcHBzLmdvb2dsZXVzZXJjb250ZW50LmNvbSIsImF1ZCI6IjEwMzAxMTUxOTQ2MjAtdXNnamQ1ZmZia2VqdDMwZWJnYjl2OWs0dmFxMTQxcXUuYXBwcy5nb29nbGV1c2VyY29udGVudC5jb20iLCJzdWIiOiIxMTEwMDUyNTQwMTU3MzQ2MDE2MjkiLCJoZCI6InF3aWtsYWJzLm5ldCIsImVtYWlsIjoic3R1ZGVudC0wMC1hMTI2NWRkYTMxOWZAcXdpa2xhYnMubmV0IiwiZW1haWxfdmVyaWZpZWQiOnRydWUsImF0X2hhc2giOiJYSFl6SGo2VzlJWUtXTExJMk1NbWFBIiwibmJmIjoxNzA4MjA4MTM3LCJuYW1lIjoic3R1ZGVudCAzYjU5ODFkMyIsInBpY3R1cmUiOiJodHRwczovL2xoMy5nb29nbGV1c2VyY29udGVudC5jb20vYS9BQ2c4b2NMLVZEU3RxSTVNdGIzQkdVTmRiZENXRVpHbGNyZjBKcjBUZmFUcU1qRVQ9czk2LWMiLCJnaXZlbl9uYW1lIjoic3R1ZGVudCIsImZhbWlseV9uYW1lIjoiM2I1OTgxZDMiLCJsb2NhbGUiOiJlbiIsImlhdCI6MTcwODIwODQzNywiZXhwIjoxNzA4MjEyMDM3LCJqdGkiOiJiOTY5M2IzMGVjZGE0ZWE3NjdhOWQ0MzhmYmE2NGYzYWNlMmJiOWRkIn0.GGPfOk6O0m9M_SgmAjbIBFXppg79sIWUsUcpYgjMKzYBfMLFRF2cg2GKoysaqk4olvPV1HJn_1pyKhZr22t6cHDuzM4ptS4kDVU_anEcEjKubeedEPlNxQLvKgZZZskMmw3T3DTdzLaLSn6IgfWBa6-3ggzlCQ17TyucKNzRxliSYm5IhpxvRZTHu9pxsVxYWqoL9z5DZXdk7WIeFU8XyQQx6YASY2vOTSFssTjNUI4OYnIxCT5FzaJjMQteiLwDQ-ubH-Mz0BGuTJC927vNmwaZgMMkNffrH0I130W4MxnGTWSCjByaD3r-csQIDjoQion8zOotbIy83WHxLOfrRA\"\n",
    "student_00_a1265dda319f@cloudshell:~ (qwiklabs-gcp-01-839553806d81)$ gcloud storage cp gs://spls/cbl455/cbl455.tar.gz .\n",
    "Copying gs://spls/cbl455/cbl455.tar.gz to file://./cbl455.tar.gz\n",
    "  Completed files 1/1 | 14.5MiB/14.5MiB                                                                                                                                                                                 \n",
    "\n",
    "Average throughput: 112.6MiB/s\n",
    "\n",
    "student_00_a1265dda319f@cloudshell:~ (qwiklabs-gcp-01-839553806d81)$ tar -xvf cbl455.tar.gz\n",
    "INPUT-JSON\n",
    "smlproxy\n",
    "\n",
    "student_00_a1265dda319f@cloudshell:~ (qwiklabs-gcp-01-839553806d81)$ export ENDPOINT=\"https://sml-api-vertex-kjyo252taq-uc.a.run.app/vertex/predict/tabular_classification\"\n",
    "\n",
    "student_00_a1265dda319f@cloudshell:~ (qwiklabs-gcp-01-839553806d81)$ export INPUT_DATA_FILE=\"INPUT-JSON\" \n",
    "\n",
    "student_00_a1265dda319f@cloudshell:~ (qwiklabs-gcp-01-839553806d81)$ ./smlproxy tabular \\\n",
    "  -a $AUTH_TOKEN \\\n",
    "  -e $ENDPOINT \\\n",
    "  -d $INPUT_DATA_FILE\n",
    "SML Tabular HTTP Response:\n",
    "2024/02/17 22:33:11 {\"model_class\":\"0\",\"model_score\":0.9999981}\n",
    "\n",
    "student_00_a1265dda319f@cloudshell:~ (qwiklabs-gcp-01-839553806d81)$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b1091d-96ff-4aac-b4fc-b16cc5853ca8",
   "metadata": {},
   "source": [
    "\n",
    "## INPUT-JSON\n",
    "\n",
    "view INPUT-JSON : use this command to view the values inside the file: INPUT-JSON\n",
    "FYI: you can also open the file using editor but looks like that option will soon be deprecated.\n",
    "\n",
    "Values inside INPUT-JSON are:\n",
    "{\"endpointId\": \"1411183591831896064\", \"instance\": \"[{age: 40.77430558, ClientID: '997', income: 44964.0106, loan: 3944.219318}]\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7c69f2-d15c-4c08-a4e3-e5b1d5f2dad2",
   "metadata": {},
   "source": [
    "## Model's output\n",
    "\n",
    "SML Tabular HTTP Response:\n",
    "2024/02/17 22:33:11 {\"model_class\":\"0\",\"model_score\":0.9999981}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
